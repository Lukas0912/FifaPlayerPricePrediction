{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./male_players.csv\"\n",
    "dataset_df = pd.read_csv(DATASET_PATH)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the columns we have to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a mean of the related attributes so as to form a summary of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['attacking_mean'] = np.mean(dataset_df[['attacking_crossing',\n",
    "                                       'attacking_finishing',\n",
    "                                       'attacking_heading_accuracy',\n",
    "                                       'attacking_short_passing',\n",
    "                                       'attacking_volleys']], axis=1)\n",
    "\n",
    "dataset_df['skill_mean'] = np.mean(dataset_df[['skill_dribbling',\n",
    "                                   'skill_curve',\n",
    "                                   'skill_fk_accuracy',\n",
    "                                   'skill_long_passing',\n",
    "                                   'skill_ball_control']], axis=1)\n",
    "\n",
    "dataset_df['movement_mean'] = np.mean(dataset_df[['movement_acceleration',\n",
    "                                      'movement_sprint_speed',\n",
    "                                      'movement_agility',\n",
    "                                      'movement_reactions',\n",
    "                                      'movement_balance']], axis=1)\n",
    "\n",
    "dataset_df['power_mean'] = np.mean(dataset_df[['power_shot_power',\n",
    "                                   'power_jumping',\n",
    "                                   'power_stamina',\n",
    "                                   'power_strength',\n",
    "                                   'power_long_shots']], axis=1)\n",
    "\n",
    "dataset_df['mentality_mean'] = np.mean(dataset_df[['mentality_aggression',\n",
    "                                       'mentality_interceptions',\n",
    "                                       'mentality_positioning',\n",
    "                                       'mentality_vision',\n",
    "                                       'mentality_penalties',\n",
    "                                       'mentality_composure']], axis=1)\n",
    "\n",
    "dataset_df['defending_mean'] = np.mean(dataset_df[['defending_marking_awareness',\n",
    "                                       'defending_standing_tackle',\n",
    "                                       'defending_sliding_tackle']], axis=1)\n",
    "\n",
    "dataset_df['goalkeeping_mean'] = np.mean(dataset_df[['goalkeeping_diving',\n",
    "                                         'goalkeeping_handling',\n",
    "                                         'goalkeeping_kicking',\n",
    "                                         'goalkeeping_positioning',\n",
    "                                         'goalkeeping_reflexes',\n",
    "                                         'goalkeeping_speed']], axis=1)\n",
    "\n",
    "columns_to_remove = ['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                      'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',\n",
    "                      'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',\n",
    "                      'movement_acceleration', 'movement_sprint_speed', 'movement_agility',\n",
    "                      'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',\n",
    "                      'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',\n",
    "                      'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                      'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',\n",
    "                      'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving',\n",
    "                      'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',\n",
    "                      'goalkeeping_reflexes', 'goalkeeping_speed']\n",
    "\n",
    "# Remove the original columns\n",
    "dataset_df.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "dataset_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use label encoding to encode categorical variables which might deicde the market value of a player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['preferred_foot'] = LabelEncoder().fit_transform(dataset_df['preferred_foot'])\n",
    "dataset_df['work_rate'] = LabelEncoder().fit_transform(dataset_df['work_rate'])\n",
    "dataset_df['body_type'] = LabelEncoder().fit_transform(dataset_df['body_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the values of the changed attrbiutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[['preferred_foot', 'work_rate', 'body_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the how the attributes might be correlated with our dependent variable **value_eur** with the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column = 'value_eur'\n",
    "\n",
    "correlations= dataset_df.corrwith(dataset_df[selected_column])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=correlations.index, y=correlations.values, palette='viridis')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.title(f'Correlation of Column {selected_column} with Other Columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the uncessary columns above a particular threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepOnlyDataOverAThreshold(data, selected_column, threshold):\n",
    "    correlations = dataset_df.corrwith(dataset_df[selected_column])\n",
    "    columns_to_keep = correlations[correlations.abs()>threshold].index.to_list()\n",
    "    columns_to_delete = list(set(dataset_df.columns.to_list()) - set(columns_to_keep))\n",
    "    return data.drop(columns=columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = keepOnlyDataOverAThreshold(dataset_df, 'value_eur', 0.1)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the rows which have N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns = dataset_df.columns.to_list()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset_df[columns] = scaler.fit_transform(dataset_df[columns])\n",
    "\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's perform the train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset_df[\"value_eur\"]\n",
    "X = dataset_df.drop(\"value_eur\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearReg(X_train, X_test, y_train, y_test):\n",
    "  model = LinearRegression()\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "  print(f'Mean Squared Error: {mse}')\n",
    "  print(f'Root Mean Squared Error: {rmse}')\n",
    "  print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearReg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Stochastic Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgdRegressor(X_train, X_test, y_train, y_test, iterations):\n",
    "  model = SGDRegressor(max_iter=iterations)\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "  print(f'Mean Squared Error: {mse}')\n",
    "  print(f'Root Mean Squared Error: {rmse}')\n",
    "  print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdRegressor(X_train, X_test, y_train, y_test, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X = X\n",
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\\\n",
    "                                            .fit_transform(small_X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearReg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdRegressor(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first re initalize the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a regressor object \n",
    "regressor = DecisionTreeRegressor(random_state = 0)  \n",
    "  \n",
    "# fit the regressor with X and Y data \n",
    "regressor.fit(X_train, y_train) \n",
    "\n",
    "#test the regressor\n",
    "y_reg = regressor.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "var_y=y_test.var()\n",
    "mse = mean_squared_error(y_test, y_reg)\n",
    "nmse=mse/var_y\n",
    "r2 = r2_score(y_test, y_reg)\n",
    "print(f'MSE= {mse}, NMSE= {nmse}, R2= {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "x_categorical = dataset_df.select_dtypes(include=['object']).apply(label_encoder.fit_transform)\n",
    "x_numerical = dataset_df.select_dtypes(exclude=['object']).values\n",
    "x = pd.concat([pd.DataFrame(x_numerical), x_categorical], axis=1).values\n",
    "\n",
    "# Fitting Random Forest Regression to the dataset\n",
    "regressor_rf = RandomForestRegressor(n_estimators=10, random_state=0, oob_score=True)\n",
    "\n",
    "# Fit the regressor with x and y data\n",
    "regressor_rf.fit(X_train, y_train)\n",
    "\n",
    "#test the regressor\n",
    "y_reg_rf = regressor_rf.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "var_y=y_test.var()\n",
    "mse = mean_squared_error(y_test, y_reg_rf)\n",
    "nmse=mse/var_y\n",
    "r2 = r2_score(y_test, y_reg_rf)\n",
    "print(f'MSE= {mse}, NMSE= {nmse}, R2= {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
